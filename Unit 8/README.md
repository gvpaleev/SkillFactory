В проекте применены:

transfer learning и fine-tuning (обучение головы -> 50% разморозка весов предобученной модели -> 75% разморозка -> 100% разморозка)
дополнительные функции callback в Keras
настройка LR
настройка параметров регуляризации полносвязного слоя нейронной сети
применен способ заполнения пропусков c помощью ImageDataAugmentor с использованием библиотеки аугментации изображений albumentations
подобраны переменные (размер картинки, батч, количество эпох)
добавлена Batch Normalization в архитектуре “головы” модели
SOTA архитектура сетей - Xception, InceptionV3, EfficientNetB5
добавлена TTA (Test Time Augmentation)
Ввиду ограничений на пользование ресурсами GPU и времязатратности самого просчета модели, не удалось протестировать следующие техники настройки модели:

настройка optimizer
настройка loss
использование внешних датасетов для дообучения модели

